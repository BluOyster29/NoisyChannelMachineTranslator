{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.language_model import LanguageModel\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.util import trigrams\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/small_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(df):\n",
    "    source = df['english'].tolist()\n",
    "    target = df['french'].tolist()\n",
    "    \n",
    "    return source, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "source, target = extract_data(small_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 313569.38it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 411569.42it/s]\n"
     ]
    }
   ],
   "source": [
    "source = pre_process(source)\n",
    "target = pre_process(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['les',\n",
       " 'délégations',\n",
       " 'qui',\n",
       " 'souhaitent',\n",
       " 's',\n",
       " 'inscrire',\n",
       " 'sur',\n",
       " 'la',\n",
       " 'liste',\n",
       " 'des',\n",
       " 'orateurs',\n",
       " 'sont',\n",
       " 'priées',\n",
       " 'de',\n",
       " 'se',\n",
       " 'mettre',\n",
       " 'en',\n",
       " 'rapport',\n",
       " 'avec',\n",
       " 'le']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(data):\n",
    "\n",
    "    vocab = {}\n",
    "    vocab['<s>'] = 0\n",
    "    vocab['<e>'] = 1\n",
    "\n",
    "    num = 2\n",
    "    for i in data:\n",
    "        for token in i:\n",
    "            if token == 0 or token == 1:\n",
    "                continue\n",
    "            elif token not in vocab:\n",
    "                vocab[token] = num\n",
    "                num += 1\n",
    "            else:\n",
    "                continue \n",
    "        \n",
    "    decode_vocab = {num : wrd for wrd, num in vocab.items()}\n",
    "    return vocab, decode_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hottify(vocab):\n",
    "    \n",
    "    hotties = {}\n",
    "    vec = np.zeros(len(vocab))\n",
    "    \n",
    "    for wrd, ind in vocab.items():\n",
    "        vec[ind] = 1\n",
    "        hotties[wrd] = vec\n",
    "        vec = np.zeros(len(vocab))\n",
    "    \n",
    "    #decode_hotties = {hot : wrd for wrd, hot in hotties.items()}\n",
    "    return hotties#, decode_hotties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/small_vectors.pickle', 'rb') as file:\n",
    "    a = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15722656,  0.24609375,  0.35351562,  0.34179688,  0.1796875 ,\n",
       "       -0.16601562, -0.16894531,  0.01672363,  0.05371094,  0.05566406,\n",
       "        0.16796875, -0.21582031, -0.07666016,  0.26171875, -0.18164062,\n",
       "        0.20019531,  0.00113678,  0.25976562,  0.07080078, -0.03173828,\n",
       "        0.04174805,  0.2265625 ,  0.06494141, -0.23730469,  0.00254822,\n",
       "        0.0612793 , -0.24902344, -0.09326172,  0.25976562, -0.15625   ,\n",
       "        0.14160156, -0.17480469, -0.14257812,  0.69921875,  0.21191406,\n",
       "       -0.2578125 ,  0.39453125,  0.2890625 , -0.11425781,  0.0859375 ,\n",
       "        0.01806641,  0.06542969,  0.04956055,  0.21972656, -0.10546875,\n",
       "       -0.10351562, -0.10058594, -0.03100586, -0.22363281,  0.11669922,\n",
       "        0.2421875 ,  0.13574219, -0.08349609,  0.25      , -0.40039062,\n",
       "       -0.0859375 , -0.09765625,  0.19042969, -0.03540039, -0.17089844,\n",
       "        0.20410156, -0.36132812,  0.00323486, -0.16601562, -0.03540039,\n",
       "       -0.10595703, -0.40625   ,  0.31640625,  0.18164062, -0.07324219,\n",
       "       -0.24804688, -0.03588867,  0.17578125,  0.14746094, -0.14160156,\n",
       "        0.11865234, -0.18261719, -0.00448608,  0.18457031,  0.12792969,\n",
       "        0.17480469, -0.3203125 ,  0.04589844,  0.03857422, -0.1328125 ,\n",
       "       -0.28515625,  0.1484375 , -0.44140625,  0.19335938,  0.24707031,\n",
       "        0.15722656, -0.43359375, -0.5546875 , -0.18066406,  0.11572266,\n",
       "       -0.13574219,  0.0300293 , -0.18652344,  0.16210938, -0.16796875,\n",
       "        0.08398438, -0.24804688, -0.171875  , -0.02062988,  0.31445312,\n",
       "        0.21972656, -0.23242188, -0.27539062,  0.3125    , -0.1015625 ,\n",
       "       -0.10644531,  0.01806641,  0.109375  ,  0.07714844,  0.10205078,\n",
       "        0.05541992,  0.37304688, -0.21679688,  0.15625   , -0.05249023,\n",
       "       -0.12988281, -0.09912109, -0.07861328, -0.10058594, -0.21875   ,\n",
       "        0.11425781, -0.34375   , -0.13964844, -0.11035156,  0.21289062,\n",
       "        0.13085938,  0.07910156,  0.4140625 , -0.26367188, -0.3515625 ,\n",
       "        0.05444336, -0.03393555, -0.00175476, -0.14257812, -0.06933594,\n",
       "       -0.20507812,  0.06835938, -0.03320312,  0.04101562, -0.15625   ,\n",
       "        0.19238281, -0.04077148, -0.16113281, -0.02270508,  0.13183594,\n",
       "        0.3359375 , -0.0324707 ,  0.05957031,  0.0612793 ,  0.18457031,\n",
       "       -0.22460938,  0.203125  ,  0.10888672, -0.1171875 , -0.06640625,\n",
       "       -0.12060547, -0.046875  ,  0.15527344, -0.13183594,  0.11279297,\n",
       "        0.02478027, -0.06542969,  0.09423828,  0.15234375,  0.1796875 ,\n",
       "       -0.23339844,  0.27929688,  0.24414062, -0.03173828,  0.16015625,\n",
       "       -0.54296875,  0.05126953, -0.09326172, -0.21484375, -0.32226562,\n",
       "       -0.2578125 ,  0.19238281,  0.25585938,  0.1484375 ,  0.13964844,\n",
       "        0.18164062,  0.16894531, -0.04272461, -0.18457031,  0.25585938,\n",
       "       -0.18847656, -0.0015564 ,  0.17089844,  0.25      ,  0.4921875 ,\n",
       "        0.24511719,  0.12158203, -0.17089844,  0.21777344, -0.2578125 ,\n",
       "        0.03173828,  0.390625  , -0.29101562, -0.05810547,  0.09472656,\n",
       "       -0.20605469,  0.37109375, -0.29882812,  0.03222656,  0.27734375,\n",
       "        0.33007812, -0.328125  , -0.33398438,  0.12695312, -0.07128906,\n",
       "        0.21972656, -0.09082031,  0.16113281,  0.22265625,  0.25585938,\n",
       "        0.12792969, -0.02612305, -0.15039062,  0.26953125,  0.078125  ,\n",
       "       -0.26367188,  0.21191406,  0.4375    ,  0.33984375, -0.09667969,\n",
       "       -0.07519531, -0.08886719, -0.01434326, -0.05957031,  0.18261719,\n",
       "       -0.36914062, -0.12597656,  0.22070312,  0.45117188, -0.02832031,\n",
       "        0.23144531,  0.25195312, -0.10351562, -0.01660156,  0.07177734,\n",
       "        0.02233887,  0.06445312,  0.12255859,  0.03759766,  0.04663086,\n",
       "       -0.12158203,  0.19824219,  0.05566406, -0.22753906, -0.18066406,\n",
       "       -0.14648438,  0.2109375 , -0.30859375,  0.03295898,  0.0213623 ,\n",
       "        0.03881836,  0.09033203,  0.24707031,  0.25      ,  0.15332031,\n",
       "       -0.07373047,  0.01397705,  0.09375   , -0.26367188,  0.00396729,\n",
       "       -0.171875  ,  0.25390625, -0.08398438, -0.06640625,  0.2265625 ,\n",
       "       -0.26953125, -0.12597656, -0.04760742, -0.29296875,  0.03149414,\n",
       "        0.06079102, -0.26757812, -0.0135498 ,  0.04956055,  0.234375  ,\n",
       "        0.15332031, -0.00708008,  0.11230469,  0.140625  ,  0.26171875,\n",
       "       -0.03588867, -0.23828125,  0.31640625, -0.24609375,  0.296875  ,\n",
       "        0.25195312,  0.05810547, -0.17480469,  0.06591797,  0.14648438],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['delegations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, decode = build_vocab(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_vocab, decode_french = build_vocab(target)\n",
    "french_hotties = hottify(french_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(lang_data):\n",
    "    return [i.split(' ') for i in tqdm(lang_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 9369.96it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 60563.19it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 29763.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting Ngrams\n",
      "Calculating Bigram MLE\n",
      "Calculating Triigram MLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "english_language_model = LanguageModel(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = Adam((net.fc1.weights, net.fc2.weights), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(50, 1, len(french_hotties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-255-736d349104a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrench\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrench_trs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtri\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mposs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menglish_language_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_likely\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mfrench_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrench\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-255-736d349104a3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrench\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrench_trs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtri\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mposs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menglish_language_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_likely\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mfrench_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrench\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'a'"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "for i, x in zip(source, target):\n",
    "    \n",
    "    trs = list(trigrams(i))\n",
    "    french_trs = list(trigrams(x))\n",
    "    \n",
    "    for tri, french in zip(trs, french_trs):\n",
    "        pre = tri[:2]\n",
    "        poss = torch.Tensor([np.array([a[i[0][-1]]]) for i in english_language_model.most_likely(pre, 50, False)])\n",
    "        french_target = french[-1]      \n",
    "        \n",
    "        y = torch.Tensor(french_hotties[french[-1]])\n",
    "        out = net.forward(poss)\n",
    "        print(torch.argmax(y))\n",
    "        print(out.shape)\n",
    "        print(torch.argmax(out, dim=1).shape)\n",
    "        error = loss(out, torch.argmax(y))\n",
    "        break\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sigmoid, Softmax\n",
    "from torch import mm\n",
    "\n",
    "\n",
    "class Net:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "\n",
    "        # input_size is the size of the vector (50 x hdden size)\n",
    "        # hidden_size can be anything really I think\n",
    "        # output_size is the final layer which is the size of the french vocabulary\n",
    "\n",
    "        self.fc1 = fc(input_size, hidden_size)\n",
    "        self.fc2 = fc(output_size, input_size)\n",
    "        self.linear = Sigmoid()\n",
    "        self.out_layer = Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1.forward(x)\n",
    "        out = self.fc2.forward(out)\n",
    "        return self.out_layer(out)\n",
    "    \n",
    "    \n",
    "class fc(Net):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    " \n",
    "        self.weights = torch.rand(output_size, input_size, requires_grad=True)\n",
    "        self.bias = torch.rand(input_size).long()\n",
    "        self.linnear = Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = mm(x, self.weights) + self.bias\n",
    "        return self.linnear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n",
      "tensor(1550)\n"
     ]
    }
   ],
   "source": [
    "for i in out:\n",
    "    print(torch.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'206'"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_french[1550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
